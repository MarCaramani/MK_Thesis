{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8084de47-1cb7-4205-97ae-77d18fa9607d",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 24px; color:slateblue; text-decoration: underline; font-weight: bold;\">**Code Diagram**</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0078cd2e-1490-4232-8a88-d01cfda014e8",
   "metadata": {},
   "source": [
    "<font color='pink'>1. ΦΟΡΤΩΣΗ DATA SET (DONE) </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecd5135-c5a7-4fb9-aeb9-904016292994",
   "metadata": {},
   "source": [
    "EXAMPLE\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Υποθέτοντας ότι το dataset σας ονομάζεται \"my_dataset\"\n",
    "dataset = load_dataset(\"your_dataset_name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea173526-4814-4b7e-90c3-e5f881d570c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "<font color='pink'>2.ΔΙΑΧΩΡΙΣΜΟΣ DATA SET ΣΕ TRAIN ΚΑΙ TEST (DONE) </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85289e9f-be97-4cf4-bf0d-93824c0e4d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Χωρίστε τα δεδομένα σας\n",
    "train_data, test_data = train_test_split(dataset[\"train\"], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "αυτο είπαμε πως θα το κανεις / θα φτιαξεις ενα ξεχωριστο data set το οποιο θα ειναι το test σου φυσικα θα εχει διαφορετικα δεδομένα \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d180e-7e9d-4898-8315-f8e250acbcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "<font color='pink'>3.ΔΗΜΙΟΥΡΓΙΑ ΤΟΥ ΜΟΝΤΕΛΟΥ (DONE) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a2b411-d1e3-4a57-bd0a-217e53263ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE \n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "πρεπει να βρεις τι μοντελο θα χρησιμοποιησεις / τι χαρακτηριστικά πρεπει ν εχει ?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6eebf-821a-4d75-a808-66b06abb7e01",
   "metadata": {},
   "source": [
    "<font color='pink'>4.ΠΡΟΕΤΟΙΜΑΣΙΑ ΔΕΔΟΜΕΝΩΝ (DONE ??? I AM NOT SURE )  </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71efdff3-7d0f-44cc-b834-0fe8a917a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE \n",
    "def prepare_data(data):\n",
    "    inputs = tokenizer(data[\"input_text\"], return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = tokenizer(data[\"target_text\"], return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    return {**inputs, **outputs}\n",
    "\n",
    "train_data = train_data.map(prepare_data)\n",
    "test_data = test_data.map(prepare_data)\n",
    "\n",
    "\n",
    "αυτο ισως και να μην χρειαστει να το κανεις πρεπει να το δεις αν χρειαζεται να τα προετοιμασεις μιας και αυτη η διαδικασια γινετε σε data set το οποιο περνεις \n",
    "απο καποια βιβλιοθηκη και οχι ενα data set που φτιαχνεις μονο σου / βεβαι μπορει να χρειαζεται προετοιμασια πρεπει να το δεις "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c083374-142c-4382-91ce-08e0fa3e8fed",
   "metadata": {},
   "source": [
    "<font color='pink'>5.ΕΚΠΑΙΔΕΥΣΗ ΤΟΥ ΜΟΝΤΕΛΟΥ</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1222deec-c8ad-430a-b71e-75f22fa72ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE \n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./summarization_model\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "ακολουθεις την διαδικασια εκπαιδευσης του μοντέλου απο το hugging face \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ebdc535-3dcd-4f89-9fc5-72da6303304d",
   "metadata": {},
   "source": [
    "<font color='red'>! ΥΠΑΡΧΟΥΝ ΠΟΛΛΕΣ ΑΛΛΕΣ ΡΥΘΜΙΣΕΙΣ ΠΟΥ ΠΡΕΠΕΙ ΝΑ ΠΡΟΣΑΡΜΟΣΕΙΣ ΑΝΑΛΟΓΑ </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2237e7-9a6b-4755-893e-47055cdebeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "τα steps που πρεπει να κοιταξεις μετά ειναι \n",
    "1. πως μπορεις να το κανεις να διαβαζει document ? ισωσ σε αυτο βοηθησει αυτο που ειχες δει στο deep learning \n",
    "2. ενα interface στο οποιο μπορεις να τρεχεις το κωδικα σου και να το κανεις πιο ωραιο/ βεβαια αυτο ειναι ενα στεπ παραπανω και δεν ξερεις καν τα βασικα χαζη \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9052dd7-2fb9-4707-b553-eda0daa3e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "ARTICLE_TO_SUMMARIZE = (\n",
    "    \"PG&E stated it scheduled the blackouts in response to forecasts for high winds \"\n",
    "    \"amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were \"\n",
    "    \"scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\n",
    ")\n",
    "inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors=\"pt\")\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=2, min_length=0, max_length=20)\n",
    "tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a73bf32-0b06-4fff-8dd5-b3eb610761f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
