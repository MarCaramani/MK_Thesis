{
 "cells": [
  {
   "cell_type": "raw",
   "id": "006a31c6-608d-4927-934e-a17b82b22787",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 24px; color:slateblue; text-decoration: underline; font-weight: bold;\">**NOTES**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c272b9f9-7c35-43cc-b8f3-01871bbc0325",
   "metadata": {},
   "source": [
    "THESIS PROCESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fab0fe4-2b10-4b47-bd3b-15de4897746f",
   "metadata": {},
   "source": [
    "<font color='deepskyblue'> 1.Figure out the task </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7698a081-fa19-45ca-a6f2-27245387c110",
   "metadata": {},
   "source": [
    "WHAT I WANT FOR REASULT ? > AUDIT AREAS , AREAS THAT I HAVE TO EXAMINE AND RELATIVE DOCUMENTS \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac39b34e-f784-43e6-8657-42ef6ee57a14",
   "metadata": {},
   "source": [
    "<font color=\"deepskyblue\"> 2.Collect data related to your task's inputs/outputs </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c243651-4e04-40bb-8ec7-e0110d6d0f16",
   "metadata": {},
   "source": [
    "IMPORT THE DATA FROM : https://www.sans.org/information-security-policy/?per-page=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a1bc1c-6745-40eb-a740-570cd329973d",
   "metadata": {},
   "source": [
    "EACH POLICY IS FOR A SPECIFIC CATEGORY, SO FOR I START I COULD RELATE THE TITLE OF EACH DOCUMENT AND THE TEXT THEY HAVE. SO ACCORDING TO THE TEXT I COULD PREDICT THE TITLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295b7473-2138-4ce0-94c4-a0a76209b9f5",
   "metadata": {},
   "source": [
    "OF THE DOCUMENT ! SO I COULD TRAIN THE MODEL TO BRING ME BACK THE TITLE OF THE DOCUMENT I WANT ... <font color=\"red\"> THIS COULD BE POSSIBLE??? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d18cee-8359-41e8-a7b3-fa106fc397cd",
   "metadata": {},
   "source": [
    "ALSO WHAT IS BETTER TO IMPORT THE DATA FROM THE INTERNET OR TO DOWNLOAD THE DATA AND TO IMPORT THEM FROM MY COMPUTER ? <font color=\"green\">(SEE LANGCHAIN) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad648f01-60cd-401a-97ec-a32056a509bf",
   "metadata": {},
   "source": [
    "  You have your own data but also you can find some data to EleutherAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0946356-def9-4c18-ae0d-2906d2331860",
   "metadata": {},
   "source": [
    "  You can generate you're own data if you dont have enough data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edb841c-9f2b-4a94-8d4c-13873056c9fc",
   "metadata": {},
   "source": [
    "<font color=\"deepskyblue\"> 3.Fined a pretrained model from the internet </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8272a8a1-89c8-4ab4-a399-ac946e3e960b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8be757a8-a2bf-427a-952f-c8e0ee5b9822",
   "metadata": {},
   "source": [
    "<font color='deepskyblue'> 4.Finetune a small model ( 400-1000 parameter model) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d9b3b8-8800-453b-9ca5-27e2d28f5e2d",
   "metadata": {},
   "source": [
    "scope of this is to finetune this model but before that you have to pretrained the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68dff9d-cddd-4cec-81e4-3d5d2758bd80",
   "metadata": {},
   "source": [
    "  <font color=\"lightblue\"> a. </font> Find a pretrained model that is close to your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507b5e5a-c284-4cb6-8e24-ac77ca5d683f",
   "metadata": {},
   "source": [
    "  <font color=\"lightblue\"> b.</font> Prepare your data in the form questions and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e97729f-7a34-4fc8-93c6-2644a8dffacb",
   "metadata": {},
   "source": [
    "  <font color=\"lightblue\"> c. </font> Finetune the model by chatting with it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa11efde-1ff5-43c2-bffe-fa8bec829a48",
   "metadata": {},
   "source": [
    "<font color=\"red\">note:</font> you can again prepare the data and start the training again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d68c9b-e516-4334-be3e-4cde24c5eaa4",
   "metadata": {},
   "source": [
    "  <font color=\"lightblue\"> d. </font> Evaluate the model / Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f2b882-6d39-4c67-b112-0784025d3bb3",
   "metadata": {},
   "source": [
    "<font color=\"deepskyblue\">5.Vary the amount of data you give the model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffc758e-587b-43bc-a6eb-2afd982f188e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8de7d59-8d46-4207-b060-747a09bda830",
   "metadata": {},
   "source": [
    "<font color=\"deepskyblue\"> 6.Evaluate your LLM to know what's going well or not </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b82fa-1e9d-4908-aa05-f5fa0f7f2423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c70f7a5-b3c5-420f-b55d-883812a09c04",
   "metadata": {},
   "source": [
    "<font color=\"deepskyblue\">7.Collect more data to improve</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9200a218-153b-4b53-b2b8-d3db4e80f270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9789a2e-b256-4e04-b1ce-da243d32013f",
   "metadata": {},
   "source": [
    "<font color=\"deepskyblue\"> 8.Increase task complexity </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa94391-0266-4653-976a-23ff80dfc087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "effb85b9-a8fb-4ea2-95a3-3ec06c65eb04",
   "metadata": {},
   "source": [
    "<font color=\"deepskyblue\"> 9.Increase model size for perfomance </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e35079-eba5-4aaf-b27a-9ffc0cee4af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f488c2fe-e804-4956-a25a-e2b1f6be3ee6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<font color=\"lime\"> 4.B </font> HOW YOU PREPARE YOURE DATA (PAGE 8 NOTES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fc1e5d-f025-4123-b864-c267b40526de",
   "metadata": {},
   "source": [
    "help from LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad5ab4d-5c2b-4384-b5a0-28bec76f9c80",
   "metadata": {},
   "source": [
    "Tokening  help by LangChain??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83b43b7-496c-4ba8-b21d-09da9cf09130",
   "metadata": {},
   "source": [
    "<font color=\"lime\">4.C </font> HOW YOU FINETUNE/TRAINEE YOUR MODEL( PAGE 8 BACK NOTES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569b7b68-326e-4864-9d57-7ac696be15ab",
   "metadata": {},
   "source": [
    "<font color=\"lime\">4.D </font> EVALUATE YOUR MODEL ( PAGE 9 BACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7722094f-f392-46d2-abfb-660fadcdceca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d84725ab-3730-45e2-94e7-c530261f40bd",
   "metadata": {},
   "source": [
    "<font size = \"4\"> LAMA 2 NOTES </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed37cc90-7031-4af8-84dd-a74ad6a47f51",
   "metadata": {},
   "source": [
    "<font color=\"red\">This will help you !!</font> https://lamini-ai.github.io/Examples/llama_v2_example/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001c6e9b-6e41-4860-96cf-d6dd27ec251a",
   "metadata": {},
   "source": [
    "https://huggingface.co/papers/2307.09288"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9931d38-f817-483e-b5b8-203cbd49b2bb",
   "metadata": {},
   "source": [
    "https://huggingface.co/blog/llama2#fine-tuning-with-peft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60c53d0-5496-41c2-b5a1-b684f7450c56",
   "metadata": {},
   "source": [
    "In this section, weâ€™ll go through different approaches to running inference of the Llama2 models. Before using these models, make sure you have requested access to one of the models in the official Meta Llama 2 repositories.\n",
    "\n",
    "Note: Make sure to also fill the official Meta form. Users are provided access to the repository once both forms are filled after few hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f32b4-477f-4475-8a0a-9baeb22936ae",
   "metadata": {},
   "source": [
    "For 7B models, we advise you to select \"GPU [medium] - 1x Nvidia A10G\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8479f70-62b6-4cf6-972b-77419ea9b7dd",
   "metadata": {},
   "source": [
    "For 13B models, we advise you to select \"GPU [xlarge] - 1x Nvidia A100\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ed8f28-860b-4617-81cf-804a37b73034",
   "metadata": {},
   "source": [
    "\n",
    "For 70B models, we advise you to select \"GPU [2xlarge] - 2x Nvidia A100\" with bitsandbytes quantization enabled or \"GPU [4xlarge] - 4x Nvidia A100\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9564e3e-8b2e-4225-bfa2-d7155260b4cc",
   "metadata": {},
   "source": [
    "https://huggingface.co/blog/rlhf Reinforcement Learning from Human Feedback (RLHF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34731610-eeae-4b65-98a4-f80705a18d09",
   "metadata": {},
   "source": [
    "![pic](THESIS/llama-rlhf.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d052186-a457-4b27-ab80-617e33ae4155",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68431b77-3bf6-46dc-8ff7-ac55dc5b728f",
   "metadata": {},
   "source": [
    "Approve email from meta "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf018db9-eabc-4558-9ed7-553e4ee879be",
   "metadata": {},
   "source": [
    "1 . Visit the Llama repository in GitHub and follow the instructions in the README to run the download.sh script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8382fe16-9775-4e21-97fa-a67e91208e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/facebookresearch/llama?fbclid=IwAR0WpeDXx_FZAKd_LiA4yVncpBatSO7-_hpAbXVvsSDD0eUsERv_wM3BZ9M\n",
    "\n",
    "https://github.com/facebookresearch/llama/blob/main/README.md?fbclid=IwAR0gyLMm_i5OEK6j96Xdl_Bh_cwYm6RxU5WsyKlSr3R6gLnfTg321XEyz-0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31712f75-214c-41ad-b08b-77f8f464f8b8",
   "metadata": {},
   "source": [
    "2.When asked for your unique custom URL, please insert the following: you will find the url in the email of yours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dda4ad-c478-4990-a1cc-8ff49517800c",
   "metadata": {},
   "source": [
    "3.Select which model weights to download\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfc5ddc-10fd-4271-b66f-fddb5788737e",
   "metadata": {},
   "source": [
    "NOTES FROM THE COURSE ON HUGGING FACE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a630a2-1fad-4fed-a593-ffbb5f5334fd",
   "metadata": {},
   "source": [
    "https://huggingface.co/models > here you can find models for NLP task that you want "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d34d5ec-37d4-45d8-a035-f8cb0f55b5ac",
   "metadata": {},
   "source": [
    "<font color=red > TRANSFORMERS CARBON FOOTPRINT </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c909399c-e7e7-40e0-b22a-f211c7727a4a",
   "metadata": {},
   "source": [
    "And this is showing a project for a (very big) model led by a team consciously trying to reduce the environmental impact of pretraining. The footprint of running lots of trials to get the best hyperparameters would be even higher.\n",
    "\n",
    "Imagine if each time a research team, a student organization, or a company wanted to train a model, it did so from scratch. This would lead to huge, unnecessary global costs!\n",
    "\n",
    "This is why sharing language models is paramount: sharing the trained weights and building on top of already trained weights reduces the overall compute cost and carbon footprint of the community.\n",
    "\n",
    "By the way, you can evaluate the carbon footprint of your modelsâ€™ training through several tools. For example ML CO2 Impact or Code Carbon which is integrated in ðŸ¤— Transformers. To learn more about this, you can read this blog post which will show you how to generate an emissions.csv file with an estimate of the footprint of your training, as well as the documentation of ðŸ¤— Transformers addressing this topic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e720d2-77c5-44b2-9293-5d7227a078ed",
   "metadata": {},
   "source": [
    "https://mlco2.github.io/impact/ > tool online that estimate based on the inpout you give to it the carbon footprint your model has "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7d1df1-a47b-46e2-8e5e-10c7039aaea7",
   "metadata": {},
   "source": [
    "https://codecarbon.io/ > tool that you can enter to your code for estimation of the carbon footprint of your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba505a64-3ce5-4c3f-9b7b-e6659458e3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
