{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30949a0e-f40b-477b-85f5-9595bdfa1429",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 24px; color:slateblue; text-decoration: underline; font-weight: bold;\">**Notes from the cources in hugging face**</span> \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e731e157-5230-45df-a044-3bd1f61ed6fe",
   "metadata": {},
   "source": [
    "<font  color=\"deepskyblue\"> Tokenizer </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc93d1e8-ed95-49a7-81c1-c108e96c5cbd",
   "metadata": {},
   "source": [
    "All this preprocessing needs to be done in exactly the same way as when the model was pretrained, so we first need to download that information from the Model Hub. To do this, we use the AutoTokenizer class and its from_pretrained() method. Using the checkpoint name of our model, it will automatically fetch the data associated with the model’s tokenizer and cache it (so it’s only downloaded the first time you run the code below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1905af-6deb-4278-84b6-9abf4a0a73f0",
   "metadata": {},
   "source": [
    "  Model Hub > https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ec6217-b422-40f7-b1d1-296554fc7e3c",
   "metadata": {},
   "source": [
    "Other notes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f61e9e-2b93-4c9a-8d25-b0372f228b2c",
   "metadata": {},
   "source": [
    "We can download our pretrained model the same way we did with our tokenizer. 🤗 Transformers provides an AutoModel class which also has a from_pretrained() method:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916ad72-50c8-4808-b235-62ab2a29d980",
   "metadata": {},
   "source": [
    "The architecture contains only the base Transformer module  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d174f2-c43b-472c-9b06-62b4004999e7",
   "metadata": {},
   "source": [
    "<font  color=\"deepskyblue\"> Tensors </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc4734-382e-46b1-8b76-b9be9d6cbd07",
   "metadata": {},
   "source": [
    "To specify the type of tensors we want to get back (PyTorch, TensorFlow, or plain NumPy), we use the return_tensors argument:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c76ccc-b4d7-4ce7-9f2a-e271427d9fbb",
   "metadata": {},
   "source": [
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64057794-8ded-4b50-955f-18c25d5b547f",
   "metadata": {},
   "source": [
    "return_tensors=\"pt\" σημαίνει οτι περιμένει να πάρει τους tensors πίσω σε μόρφη της pytorch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac41b180-444c-4a40-a32b-81428d0ad142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
